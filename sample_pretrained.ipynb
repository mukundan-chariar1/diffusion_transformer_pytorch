{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a3a0e02",
      "metadata": {
        "id": "9a3a0e02"
      },
      "outputs": [],
      "source": [
        "!pip -q install --upgrade diffusers transformers accelerate safetensors torchvision huggingface_hub\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Afzt84vv-fll",
      "metadata": {
        "id": "Afzt84vv-fll"
      },
      "outputs": [],
      "source": [
        "import os, requests, importlib.util, sys\n",
        "\n",
        "raw_url=\"https://raw.githubusercontent.com/huggingface/diffusers/main/examples/community/pipeline_flux_with_cfg.py\"\n",
        "os.makedirs(\"/content/flux_cfg\", exist_ok=True)\n",
        "open(\"/content/flux_cfg/pipeline_flux_with_cfg.py\", \"w\").write(requests.get(raw_url).text)\n",
        "\n",
        "spec=importlib.util.spec_from_file_location(\"pipeline_flux_with_cfg\", \"/content/flux_cfg/pipeline_flux_with_cfg.py\")\n",
        "mod=importlib.util.module_from_spec(spec); sys.modules[spec.name]=mod; spec.loader.exec_module(mod)\n",
        "FluxCFGPipeline=mod.FluxCFGPipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b95a2b40",
      "metadata": {
        "id": "b95a2b40"
      },
      "outputs": [],
      "source": [
        "import math, shutil\n",
        "from typing import Dict, Any\n",
        "import torch\n",
        "import torchvision.utils as vutils\n",
        "from diffusers import FluxPipeline\n",
        "\n",
        "@torch.no_grad()\n",
        "def decode_and_save_grid(pipe: FluxPipeline, latents: torch.Tensor, path: str, nrow: int=10):\n",
        "    vae=pipe.vae\n",
        "    scaling=getattr(vae.config, \"scaling_factor\", 0.18215)\n",
        "    imgs01=vae.decode(latents/scaling).sample.clamp_(0, 1)\n",
        "    grid=vutils.make_grid(imgs01, nrow=nrow)\n",
        "    vutils.save_image(grid, path)\n",
        "\n",
        "model_id=\"black-forest-labs/FLUX.1-dev\"  # requires HF acceptance/login\n",
        "dtype=torch.bfloat16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37ff437d",
      "metadata": {
        "id": "37ff437d"
      },
      "outputs": [],
      "source": [
        "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using:\", device, dtype)\n",
        "\n",
        "pipe=FluxPipeline.from_pretrained(model_id, torch_dtype=dtype)\n",
        "\n",
        "pipe.enable_model_cpu_offload()\n",
        "# pipe.set_progress_bar_config(disable=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ffddcae",
      "metadata": {
        "id": "0ffddcae"
      },
      "outputs": [],
      "source": [
        "prompt=\"indian institute of science\"\n",
        "steps=20\n",
        "panels=10\n",
        "guidance=3.5\n",
        "width=256\n",
        "height=256\n",
        "seed=42\n",
        "num_images=100\n",
        "nrow=10\n",
        "\n",
        "out_dir=f\"/content/viz_flux_{prompt.replace(' ', '_')}\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "capture_idxs=set(torch.linspace(0, steps - 1, panels, dtype=torch.long).tolist())\n",
        "saved={}\n",
        "\n",
        "def on_step_end(pipe, step: int, timestep: int, kwargs: dict) -> dict:\n",
        "    if step in capture_idxs and \"latents\" in kwargs:\n",
        "        lat=kwargs[\"latents\"]\n",
        "\n",
        "        vae_latents=pipe._unpack_latents(lat, height, width, pipe.vae_scale_factor)\n",
        "\n",
        "        path=os.path.join(out_dir, f\"step_{step:03d}.png\")\n",
        "        decode_and_save_grid(pipe, vae_latents, path, nrow=nrow)\n",
        "        saved[step]=path\n",
        "    return kwargs\n",
        "\n",
        "_=pipe(\n",
        "    prompt=prompt,\n",
        "    height=height,\n",
        "    width=width,\n",
        "    guidance_scale=guidance,\n",
        "    num_inference_steps=steps,\n",
        "    num_images_per_prompt=num_images,\n",
        "    output_type=\"pil\",\n",
        "    callback_on_step_end=on_step_end,\n",
        "    callback_on_step_end_tensor_inputs=[\"latents\"],\n",
        ")\n",
        "\n",
        "if saved:\n",
        "    last=max(saved)\n",
        "    shutil.copyfile(saved[last], os.path.join(out_dir, \"final.png\"))\n",
        "print(f\"Saved {len(saved)} panels to {out_dir}\")\n",
        "\n",
        "!zip {out_dir}.zip -r {out_dir}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "096bba18",
      "metadata": {
        "id": "096bba18"
      },
      "outputs": [],
      "source": [
        "import os, math, torch, numpy as np, torchvision.utils as vutils\n",
        "from typing import List\n",
        "from PIL import Image\n",
        "\n",
        "prompt=\"umbrella\"\n",
        "neg=\"\"\n",
        "height, width=256, 256\n",
        "steps=16\n",
        "imgs_per_grid=8\n",
        "nrow=4\n",
        "w_cfg_max=10\n",
        "out_dir=\"/content/final_image_cfg_compare\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "tag=prompt.replace(\" \", \"_\")\n",
        "\n",
        "dtype=torch.bfloat16\n",
        "pipe=FluxCFGPipeline.from_pretrained(model_id, torch_dtype=dtype)\n",
        "pipe.enable_model_cpu_offload()\n",
        "pipe.set_progress_bar_config(disable=True)\n",
        "\n",
        "def pil_grid(images: List[Image.Image], path: str, nrow: int):\n",
        "    tens=[torch.from_numpy(np.array(im)).permute(2,0,1).float().div_(255) for im in images]\n",
        "    grid=vutils.make_grid(torch.stack(tens, 0), nrow=nrow)\n",
        "    vutils.save_image(grid, path)\n",
        "\n",
        "def gen_imgs(text: str, num: int, seed0: int, **kwargs) -> List[Image.Image]:\n",
        "    out=[]\n",
        "    for i in range(num):\n",
        "        g=torch.Generator(device=\"cpu\").manual_seed(seed0 + i)\n",
        "        im=pipe(prompt=text, height=height, width=width,\n",
        "                  num_inference_steps=steps, generator=g,\n",
        "                  output_type=\"pil\", **kwargs).images[0]\n",
        "        out.append(im)\n",
        "    return out\n",
        "\n",
        "imgs_uncond=gen_imgs(\"\", imgs_per_grid, seed0=0,\n",
        "                        negative_prompt=None,\n",
        "                        guidance_scale=1.0,\n",
        "                        true_cfg=1e-6)\n",
        "\n",
        "imgs_cond=gen_imgs(prompt, imgs_per_grid, seed0=0,\n",
        "                      negative_prompt=neg,\n",
        "                      guidance_scale=1.0,\n",
        "                      true_cfg=1e-6)\n",
        "\n",
        "pil_grid(imgs_uncond, os.path.join(out_dir, f\"{tag}_uncond.png\"), nrow)\n",
        "pil_grid(imgs_cond, os.path.join(out_dir, f\"{tag}_cond.png\"), nrow)\n",
        "\n",
        "del imgs_uncond, imgs_cond\n",
        "\n",
        "for w_cfg in range(w_cfg_max+1):\n",
        "    imgs_cfg=gen_imgs(prompt, imgs_per_grid, seed0=0,\n",
        "                        negative_prompt=neg,\n",
        "                        guidance_scale=1.0,\n",
        "                        true_cfg=float(w_cfg))\n",
        "\n",
        "    pil_grid(imgs_cfg, os.path.join(out_dir, f\"{tag}_truecfg_w{str(w_cfg)}.png\"), nrow)\n",
        "\n",
        "    del imgs_cfg\n",
        "\n",
        "!zip {out_dir}.zip {out_dir}/*"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
